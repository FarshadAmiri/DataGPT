source vllm-venv/bin/activate

python -m vllm.entrypoints.openai.api_server \
--host 0.0.0.0 --port 9002 \
--model /home/user_1/models/Qwen2.5-7B-Instruct-AWQ \
--served-model-name Qwen2.5-7B-Instruct-AWQ \
--dtype auto \
--quantization awq \
--max-model-len 24000 \
--gpu-memory-utilization 0.80 \
--enforce-eager \
--swap-space 2

--------------------------------------------------------------------

model source: ~/.cache/huggingface/hub/models--Qwen--Qwen3-4B-AWQ



