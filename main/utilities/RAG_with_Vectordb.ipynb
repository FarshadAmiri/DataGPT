{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "import accelerate\n",
    "import torch\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring text generation model, tokenizer, computational device and optional streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 SUPER'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting device\n",
    "gpu=0\n",
    "device = torch.device(f\"cuda:{gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model name and hf token\n",
    "name = \"TheBloke/Llama-2-7b-Chat-GPTQ\"\n",
    "# name = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\"\n",
    "\n",
    "# hugginf face auth token\n",
    "# file_path = \"../../huggingface_credentials.txt\"\n",
    "# with open(file_path, \"r\") as file:\n",
    "#     auth_token = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(name\n",
    "    # ,cache_dir='./model/'\n",
    "    # ,use_auth_token=auth_token\n",
    "    ,device_map='cuda'                 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin D:\\NLP 1\\venv\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.dll\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = AutoModelForCausalLM.from_pretrained(name\n",
    "    ,cache_dir=r\"C:\\Users\\user2\\.cache\\huggingface\\hub\"\n",
    "    # ,cache_dir='./model/'\n",
    "    # ,use_auth_token=auth_token\n",
    "    ,device_map='cuda'  \n",
    "    # , torch_dtype=torch.float16\n",
    "    # ,low_cpu_mem_usage=True\n",
    "    # ,rope_scaling={\"type\": \"dynamic\", \"factor\": 2}\n",
    "    # ,load_in_8bit=True,\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_inference(plain_text, model, tokenizer, device, streamer=None, max_length=4000, ):\n",
    "    input_ids = tokenizer(\n",
    "        plain_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        )['input_ids'].to(device)\n",
    "    \n",
    "    output_ids = model.generate(input_ids\n",
    "                        ,streamer=streamer\n",
    "                        ,use_cache=True\n",
    "                        ,max_new_tokens=float('inf')\n",
    "                       )\n",
    "    answer = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating texts using a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat are the steps to train a machine learning model? explain in less than 100 words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mllm_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m res\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mllm_inference\u001b[1;34m(plain_text, model, tokenizer, device, streamer, max_length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllm_inference\u001b[39m(plain_text, model, tokenizer, device, streamer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m, ):\n\u001b[0;32m      2\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[0;32m      3\u001b[0m         plain_text,\n\u001b[0;32m      4\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m      7\u001b[0m         )[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m,\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                       \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     answer \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(output_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1606\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[0;32m   1590\u001b[0m         input_ids,\n\u001b[0;32m   1591\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1602\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1603\u001b[0m     )\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[0;32m   1605\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2454\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2454\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2457\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2462\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:1038\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1035\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1050\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:925\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    921\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    922\u001b[0m         create_custom_forward(decoder_layer), hidden_states, attention_mask, position_ids\n\u001b[0;32m    923\u001b[0m     )\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 925\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:635\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[0;32m    632\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 635\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:373\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[0;32m    370\u001b[0m key_states \u001b[38;5;241m=\u001b[39m repeat_kv(key_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[0;32m    371\u001b[0m value_states \u001b[38;5;241m=\u001b[39m repeat_kv(value_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[1;32m--> 373\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_weights\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, q_len, kv_seq_len):\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention weights should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;250m \u001b[39mq_len,\u001b[38;5;250m \u001b[39mkv_seq_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_weights\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    379\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = \"what are the steps to train a machine learning model? explain in less than 100 words\"\n",
    "res = llm_inference(text, model, tokenizer, device, streamer=streamer,)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, get_response_synthesizer\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index import set_global_service_context\n",
    "from llama_index import ServiceContext\n",
    "from llama_index import VectorStoreIndex, download_loader\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.vector_stores import MilvusVectorStore\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"test_vdb/vdb_test1\"\n",
    "path = r\"D:\\NLP 1\\RAG-webapp\\collections\\collection_C1\"\n",
    "db = chromadb.PersistentClient(path=path)\n",
    "\n",
    "# get collection\n",
    "chroma_collection = db.get_or_create_collection(\"default\")\n",
    "\n",
    "# assign chroma as the vector_store to the context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a system prompt\n",
    "system_prompt = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as\n",
    "helpfully as possible, while being safe.\n",
    "If a question does not make any sense, or is not factually coherent, explain\n",
    "why instead of answering something not correct. If you don't know the answer\n",
    "to a question, please express that you do not have informaion or knowledge in\n",
    "that context and please don't share false information.\n",
    "Try to be exact in information and numbers you tell.\n",
    "Your goal is to provide answers based on the information provided and your other\n",
    "knowledge.<</SYS>>\n",
    "\"\"\"\n",
    "\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"{query_str} [/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceLLM(context_window=4096,\n",
    "                     max_new_tokens=512,\n",
    "                     system_prompt=system_prompt,\n",
    "                     query_wrapper_prompt=query_wrapper_prompt,\n",
    "                     model=model,\n",
    "                     tokenizer=tokenizer)\n",
    "\n",
    "embeddings = LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new service context instance\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    "    llm=llm,\n",
    "    embed_model=embeddings\n",
    ")\n",
    "\n",
    "# And set the service context\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert a single document into the vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 1566b89d-6d46-48c0-a101-a33841c9bb42\n",
      "Text: 2023  APR  Eye of the Storm: The  Impact of Climate  Shocks on\n",
      "Inflation  and Growth  Serhan Cevik and Jo√£o Tovar Jalles  WP/23/87\n",
      "Doc ID: 6dd18d1c-3600-469e-b182-7258c6d085e6\n",
      "Text: ¬© 2023 International Monetary Fund  WP/23/87 IMF Working Paper\n",
      "European Department  Eye of the Storm: The Impact of Climate Shocks on\n",
      "Inflation and Growth  Prepared by Serhan Cevik and Jo√£o Tovar Jalles1\n",
      "Authorized for distribution by Bernardin Akitoby  April 2023  IMF\n",
      "Working Papers describe research in progress by the author(s) and are\n",
      "publi...\n",
      "Doc ID: b600f50d-41bc-4079-8ce1-09ea1310e96f\n",
      "Text: I.   INTRODUCTION  Climate change is a multifaceted and evolving\n",
      "phenomenon and a major source of uncertainty  for the global economy\n",
      "and financial markets.2 The global surface temperature has already\n",
      "jumped more than 1.1 degrees Celsius (¬∞C) compared with the\n",
      "preindustrial average, escalating  the frequency and severity of\n",
      "weather-related natu...\n",
      "Doc ID: bd345399-4db4-41e5-b8ec-f1891c3548cc\n",
      "Text: 4  reducing wealth and income and thereby consumption and\n",
      "investment; (iv) affecting  transportation infrastructure and\n",
      "distribution costs. Furthermore, these transmission channels  vary\n",
      "significantly with the level of economic development and\n",
      "diversification across countries.   Empirical findings presented in\n",
      "this paper should be treated as a l...\n",
      "Doc ID: 7b9f8ea8-2a80-4c8e-b56c-244352f9557b\n",
      "Text: 5  factors. Neoclassical and endogenous growth theories explain\n",
      "these differences in growth  performance mainly by the accumulation of\n",
      "physical and human capital and technological  advancements (Solow,\n",
      "1956; Romer, 1986, 1990; Lucas, 1988). Using cross-country analysis,\n",
      "Easterly and Wetzel (1989), Barro (1991; 2003), Barro and Sala-i-\n",
      "Martin (19...\n",
      "Doc ID: 2e5c76df-b1ed-41fb-a3c3-b69915a5eeea\n",
      "Text: 6  underwriting fees and initial yields to issue long-term\n",
      "municipal bonds compared to counties  unlikely to be affected by\n",
      "climate change.   With regards to the impact of climate change on\n",
      "consumer price inflation, there is a small but  growing literature. A\n",
      "few studies look at the impact of natural hazards on prices (Parker,\n",
      "2018;  Heinen et a...\n",
      "Doc ID: 9570b383-5131-4410-84fa-cd85266f4974\n",
      "Text: 7  develop a more granular analysis, we also use the intensity\n",
      "of climate-related natural disasters as  measured by the number of\n",
      "deaths scaled by population.  Following the literature as summarized\n",
      "in Botzen et al. (2019),  we introduce a number of control  variables\n",
      "in our regression analysis, including real GDP per capita, the output\n",
      "gap, tra...\n",
      "Doc ID: 793cbcc2-de10-4375-b1d6-d0a3832c0949\n",
      "Text: 8  control variables including up to two lags of climate shocks,\n",
      "of the relevant dependent variable  and two lags of the output gap\n",
      "obtained via the HP filter.7   This equation is estimated for three\n",
      "different measures of inflation‚Äîheadline CPI, core CPI, and  food\n",
      "prices‚Äîand real GDP growth. In terms of the main variable of interest\n",
      "(ùê∂ùëÜùëñ,ùë°), we...\n",
      "Doc ID: 169f6ffc-087d-4950-96a4-fc784dfafa4c\n",
      "Text: 9  We choose ùõºÔøΩÔøΩÔøΩ = 1.5.13 This approach permits a direct test\n",
      "of whether the effect of climate shocks  varies across different\n",
      "regimes such as recessions and expansions and allows the effect of\n",
      "climate  shocks to change smoothly between recessions and expansions\n",
      "by considering a continuum of  states to compute IRFs, thus making the\n",
      "response mor...\n",
      "Doc ID: 790ed996-a56e-4712-aa9a-de4364126950\n",
      "Text: 10  since the shock, at which point headline inflation is 3.5\n",
      "percentage points lower than if the  temperature shock had not\n",
      "happened. A drought shock, on the other hand, results in an\n",
      "immediate increase in headline inflation above its initial level,\n",
      "which lasts over the long term and  amounts to about 1.5 percentage\n",
      "points compared to if the ...\n",
      "Doc ID: 2510e2c2-bbd3-41ee-9b92-048e833e726f\n",
      "Text: 11  and food inflation shows significant variation in magnitude\n",
      "and pattern across country groups.  Extreme temperatures lead to\n",
      "higher and more volatile core and food inflation in advanced\n",
      "economies, whereas it has the opposite and sustained impact in\n",
      "developing countries. A drought  shock appears to be disinflationary\n",
      "with a volatile pattern ...\n",
      "Doc ID: 9c005ecb-a597-4a17-8908-c33e00dcbe78\n",
      "Text: 12  run in the case of developing countries. The impact of\n",
      "storms on food inflation, on the other  hand, exhibits an opposite\n",
      "pattern in advanced economies (declining) and developing countries\n",
      "(increasing), but converges to insignificance over the long run in\n",
      "both country groups.  Figure 4. Impact of Climate Shocks on Core\n",
      "Inflation: Role of th...\n",
      "Doc ID: e55fa4f4-8c40-4033-a8f7-aa09678e0333\n",
      "Text: 13  We also explore the possibility of nonlinear effects of\n",
      "climate shocks on inflation by looking at  two particular dimensions:\n",
      "(i) the position of a given economy in the business cycle at the time\n",
      "the climate shock hits; and (ii) the level of public debt as a proxy\n",
      "of fiscal space to cushion the   impact of climate shocks. First, as\n",
      "presente...\n",
      "Doc ID: c6ad7bdd-a539-4c45-a646-1436b7fcdf17\n",
      "Text: 14  plays an important role in shaping the impact of weather-\n",
      "related disasters on core inflation, but   magnitude and long-run\n",
      "pattern depend on the exact nature of the shock. Second, as presented\n",
      "in Figure 5, we find that climate shocks have a differentiated effect\n",
      "on core inflation depending  on the level of fiscal space as measured\n",
      "by low le...\n",
      "Doc ID: df49bf68-8ed7-40e8-b562-c131153461a2\n",
      "Text: 15  Figure 7. Impact of Climate Shocks on Headline Inflation:\n",
      "Excluding Country Fixed Effects    Note: The charts show IRFs using\n",
      "the LP method. x-axis in years; t=0 is the year preceding the climate\n",
      "shock; t=1  is the first year of impact. The solid black line denotes\n",
      "the response to a climate shock, the dark grey area denotes\n",
      "90-percent confi...\n",
      "Doc ID: 7e66684b-d150-4ff7-bef2-970e0f043714\n",
      "Text: 16  Figure 9. Impact of Climate Shocks on Headline Inflation:\n",
      "Disaster Intensity    Note: The charts show IRFs using the LP method.\n",
      "x-axis in years; t=0 is the year preceding the climate shock; t=1  is\n",
      "the first year of impact. The solid black line denotes the response to\n",
      "a climate shock, the dark grey area denotes  90-percent confidence\n",
      "bands a...\n",
      "Doc ID: 76ae4d28-caf9-459c-9b8c-3ca4cf9a8f6c\n",
      "Text: 17  We also explore the nonlinear effects of weather-related\n",
      "natural disasters on economic growth  by taking into account the state\n",
      "of the economy and the level of public debt as a proxy of fiscal\n",
      "space at the time the climate shock hits. These results, presented in\n",
      "Figure 13-14, show that both  the state of the economy and available\n",
      "fiscal spa...\n",
      "Doc ID: 6d5823fc-ff68-4b07-ae5b-36d48e88893a\n",
      "Text: 18  Figure 11. Impact of Climate Shocks on Growth: Income Group\n",
      "Advanced Economies  Developing Countries      Note: The charts show\n",
      "IRFs using the LP method. x-axis in years; t=0 is the year preceding\n",
      "the climate shock; t=1  is the first year of impact. The solid black\n",
      "line denotes the response to a climate shock, the dark grey area\n",
      "denotes 90...\n",
      "Doc ID: 69bb5f59-cc85-46a7-8702-94f12a1b1bee\n",
      "Text: 19  Figure 13. Impact of Climate Shocks on Growth: Role of the\n",
      "Business Cycle  Advanced Economies  Developing Countries\n",
      "Note: The charts present IRFs based on Equation [2]. x-axis in years;\n",
      "t=0 is the year of the climate shock; t=1 is  the first year of\n",
      "impact. The solid black line denotes the response to a climate shock;\n",
      "the dark a...\n",
      "Doc ID: 6632ff2e-d44e-4889-9beb-5bb489bda823\n",
      "Text: 20  Figure 14. Impact of Climate Shocks on Growth: Role of\n",
      "Fiscal Space  Advanced Economies  Developing Countries\n",
      "Note: The charts present IRFs based on Equation [2]. x-axis in years;\n",
      "t=0 is the year of the climate shock; t=1 is  the first year of\n",
      "impact. The solid black line denotes the response to a climate shock;\n",
      "the dark and lig...\n",
      "Doc ID: 527e5796-13b1-4ef1-a49d-8cf8fc259f1e\n",
      "Text: 21  VI.   CONCLUSION  Climate change is the defining challenge\n",
      "of our time. In this paper, we empirically investigate the  impact of\n",
      "weather-related natural disasters on consumer price inflation and\n",
      "economic growth,  using a large panel of 173 countries during the\n",
      "period 1970‚Äì2020. The analysis based on the LP  method shows that\n",
      "inflation and gr...\n",
      "Doc ID: f1a5b36a-cc05-43e5-bbd5-1d5e74042f2c\n",
      "Text: 22  households whose consumption basket consists of goods and\n",
      "services that are more likely to  experience an increase in inflation\n",
      "and loss of income in the aftermath of natural disasters will be  more\n",
      "adversely affected compared to households whose consumption is\n",
      "proportionately less  dependent on such products and income is not\n",
      "subject to a n...\n",
      "Doc ID: e5fa457d-b8dd-4b09-8899-2521235213c9\n",
      "Text: 23  REFERENCES  Abiad, A., D. Furceri, and P. Topalova, 2016,\n",
      "‚ÄùThe Macroeconomic Effects of Public Investment:  Evidence from\n",
      "Advanced Economies,‚Äù Journal of Macroeconomics, Vol. 50, pp. 224‚Äì240.\n",
      "Acemoglu, D., S. Johnson, and J. Robinson, 2002, ‚ÄúReversal of Fortune:\n",
      "Geography and  Institutions in the Making of the Modern World Income\n",
      "Distributi...\n",
      "Doc ID: 2db54b2b-64a6-4a51-ab1f-04ef5e43be07\n",
      "Text: 24  Bansal, R., D. Kiku, and M. Ochoa, 2016, ‚ÄúPrice of Long-Run\n",
      "Temperature Shifts in Capital  Markets,‚Äù NBER Working Paper No. 22529\n",
      "(Cambridge, MA: National Bureau of Economic  Research).   Barro, R.,\n",
      "1991, ‚ÄúEconomic Growth in a Cross-Section of Countries,‚Äù Quarterly\n",
      "Journal of  Economics, Vol. 106, pp. 407‚Äì443.  Barro, R., 2003,\n",
      "‚ÄúDeterminants...\n",
      "Doc ID: 8a0fb48c-f8bb-4b16-a9aa-69bb7da84e78\n",
      "Text: 25  Campillo, M., and J. Miron, 1997, ‚ÄúWhy Does Inflation Differ\n",
      "Across Countries?‚Äù NBER Working  Paper No. 5540 (Cambridge, MA:\n",
      "National Bureau of Economic Research).  Catao, L., and M. Terrones,\n",
      "2005, ‚ÄúFiscal Deficits and Inflation,‚Äù Journal of Monetary Economics,\n",
      "Vol. 52, pp. 529‚Äì554.  Cecchetti, S., and S. Krause, 2002, ‚ÄúCentral\n",
      "Bank Struct...\n",
      "Doc ID: 9a103f07-a021-43cd-9d1b-716839e250a2\n",
      "Text: 26  Dell, M., B. Jones, and B. Olken, 2012, ‚ÄúTemperature Shocks\n",
      "and Economic Growth: Evidence from  the Last Half Century,‚Äù American\n",
      "Economic Journal: Macroeconomics, Vol. 4, pp. 66‚Äì95.  De Winne, J.,\n",
      "and G. Peersman, 2018, ‚ÄúAgricultural price shocks and business cycles:\n",
      "a global  warning for advanced economies,‚Äù Ghent University Working\n",
      "Paper N...\n",
      "Doc ID: 3ade3a9e-a048-43c8-b9ae-72b1ff418ac6\n",
      "Text: 27  Hamilton, J. (2018), ‚ÄúWhy You Should Never Use the Hodrick-\n",
      "Prescott Filter,‚Äù Review of Economics  and Statistics, Vol. 100(5),\n",
      "pp. 831-843.  Hausmann, R., M. Gavin, C. Pages, and E. Stein, 1999,\n",
      "‚ÄúFinancial Turmoil and Choice of Exchange  Rate Regime,‚Äù IDB Working\n",
      "Paper No. 331 (Washington, DC: Inter-American  Development Bank).\n",
      "Heinen, A.,...\n",
      "Doc ID: 3ae09861-af68-4eed-960f-a9891a474b2c\n",
      "Text: 28  Kahn, M., K. Mohaddes, R. Ng, M. Pesaran, M. Raissi, and\n",
      "J-C. Yang, 2021, ‚ÄúLong-Term  Macroeconomic Effects of Climate Change:\n",
      "A Cross-Country Analysis,‚Äù Energy Economics,  105624.  King, R., and\n",
      "R. Levine, 1993, ‚ÄúFinance, Entrepreneurship, and Growth: Theory and\n",
      "Evidence,‚Äù  Journal of Monetary Economics, Vol. 32, pp. 513‚Äì542.\n",
      "Knack, S., an...\n",
      "Doc ID: a15d81b0-e66a-4d82-9b64-8ed74e6de434\n",
      "Text: 29  Painter, M., 2020, ‚ÄúAn Inconvenient Cost: The Effects of\n",
      "Climate Change on Municipal Bonds,‚Äù  Journal of Financial Economics,\n",
      "Vol. 135, pp. 468‚Äì482.  Parker, M., 2018, ‚ÄúThe Impact of Disasters on\n",
      "Inflation,‚Äù Economics of Disasters and Climate  Change, Vol. 2, pp.\n",
      "21‚Äì48.  Posen, A., 1998, ‚ÄúCentral Bank Independence and Disinflation\n",
      "Credibilit...\n",
      "Doc ID: 59a25929-b1b2-40c0-9dbf-4b29624ed7a8\n",
      "Text: 30  Skidmore, M., and H. Toya, 2002, ‚ÄúDo Natural Disasters\n",
      "Promote Long-Run Growth?‚Äù Economic  Inquiry, Vol. 40, pp. 664‚Äì687.\n",
      "Solow, R., 1956, ‚ÄúA Contribution to the Theory of Economic Growth,‚Äù\n",
      "Oxford Review of Economic  Policy, Vol. 23, pp. 3‚Äì14.  Stern, N.,\n",
      "2007, The Economics of Climate Change: The Stern Review (Cambridge:\n",
      "Cambridge  Univers...\n",
      "Doc ID: d70c9570-61b9-439c-a5b6-542ae2b4251c\n",
      "Text: 31  APPENDIX    Table A1. Summary Statistics    Variable\n",
      "observations  mean  Standard  deviation  minimum  maximum  Real GDP\n",
      "growth (not in percent)  6890  0.032  0.057  -1.02  0.802  Inflation\n",
      "rate (headline) (not in  percent)  6129  0.99  0.25  -0.370  5.223\n",
      "Public debt (% GDP)  5865  57.19  47.17  0.002  677.18  Real GDP per\n",
      "capita (log)  ...\n",
      "Doc ID: 497fbb7d-7164-4498-af40-6190e9b1a71e\n",
      "Text: Table A2. Coefficient Estimates underlying Figure 1    Horizon k\n",
      "(1)  (2)  (3)  (4)  (5)  (6)  (7)  (8)  (9)  (10)  (11)  (12)  (13)\n",
      "(14)  (15)  Shock type  Extreme temperature  Drought  Storm\n",
      "shock  -0.0025  -0.0089*  -0.0192**  -0.0297**  -0.0320**  0.0051**\n",
      "0.0101**  0.0088  0.0095  0.0056  0.0016  -0.001...\n",
      "Doc ID: a075c8ab-09fd-40df-b4e0-ab23729d18f7\n",
      "Text: 33  Table A3. Coefficient Estimates underlying Figure 10\n",
      "Horizon k  (1)  (2)  (3)  (4)  (5)  (6)  (7)  (8) (9)  (10)  (11)\n",
      "(12)  (13)  (14)  (15)  Shock type  Extreme temperature  Drought\n",
      "Storm  shock  -0.0011 -0.0026  -0.0057  -0.0108**  -0.0137**  -0.0025\n",
      "-0.0011  -0.0016 0.0002  0.0012  -0.0011  0.0016  0.0009  -0.0003\n",
      "0.0018  (0.002) (0...\n"
     ]
    }
   ],
   "source": [
    "PyMuPDFReader = download_loader(\"PyMuPDFReader\")\n",
    "loader = PyMuPDFReader()\n",
    "\n",
    "# Load documents\n",
    "# doc_dir = r\"D:\\NLP 1\\RAG-webapp\\documents_db\\Sattelite imagery article scripts.pdf\"\n",
    "doc_dir = r\"C:\\Users\\user2\\Desktop\\RAG_Docs\\Climate_change_20232.pdf\"\n",
    "document = loader.load(file_path=Path(doc_dir), metadata=False)\n",
    "\n",
    "# Create indexes\n",
    "for doc in document:\n",
    "    print(doc)\n",
    "    # index.insert(doc, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert directory of documents into the vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some documents\n",
    "documents = SimpleDirectoryReader(r\"C:\\Users\\user2\\Desktop\\RAG_Docs\").load_data()\n",
    "\n",
    "# create your index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "########## Or ###########\n",
    "#Customizing query engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=3,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(streaming=True)\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.0)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NodeWithScore(node=TextNode(id_='c8ed8ecb-3135-4c5e-a3ba-6bdee40ce423', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='f7b86ebc0736c6d0519f87124fd6b20d3434e57304341e9edee468ade70c3a23')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='The UAE is Iran‚Äôs second -largest trade partner. The trade between Iran and the UAE has \\nrecovered from a pandemic slump of $11 billion in 2020/2021 to $24 billion in the 12 \\nmonths ending in March, according to Iranian data.  \\nThe trade between the two sides has surpassed the $22 billion recorded in 2012 before \\nU.S. -led sanctions were imposed on the Iranian economy.  \\nIranian officials have said they are now targeting a further increase in bilateral trade \\ntowards $30 billion in the next two years.  \\n‚ÄúPressure from the UAE central bank has decreased and some Emirati banks have started \\nopening bank accounts,‚Äù said Masoud Daneshmand, a former head of the Iran -UAE \\nChamber of Commerce. ‚ÄúCurrently, some Iranian companies that used to be in the UAE \\nbut had become inactive have become active again. Some new companies have also \\nstarted business.‚Äù  \\nIn diplomatic exchanges, Iranian officials have been asking their Emirati counterparts to \\nfind new mechanisms for financing trade, according to people briefed on these \\nconversations.  \\n‚ÄúOur economic relationship with Iran has long been of major importance,‚Äù said the UAE‚Äôs \\neconomy ministry. ‚ÄúThe UAE‚Äôs trade with Iran is conducted in full compliance with global \\nrules and standards.‚Äù  \\nFor years there have been self -imposed restrictions on business with Iran, but these have \\nbeen gradually eased in recent years, a UAE -based businessman said. ‚ÄúThere‚Äôs a sense of \\nmore openness.‚Äù  \\nIran and the United Arab Emirates have agreed to sign new memorandums of \\nunderstanding (MOUs) on the avoidance of double taxation and facilitation of mutual \\ninvestment.  \\nThe decision was made during a meeting between Iranian Minister of Finance and \\nEconomic Affairs Ehsan Khandouzi and UAE Minister of State for Financial Affairs \\nMohamed bin Hadi Al Hussaini on the sidelines of the annual meeting of the Islamic \\nDevelopment Bank (IsDB) Board of Executive Directors in Jeddah in mid -May.  \\nDuring the meeting, the officials emphasized increasing cooperation in the fields of trade \\nand foreign investment; in this regard, it was decided that appropriate measures should be \\nimplemented soon in order to sign agreements on facilitating foreign investment and \\navoidance of double taxation between the countries.', start_char_idx=0, end_char_idx=2268, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5299779336192382),\n",
      " NodeWithScore(node=TextNode(id_='e7f2d6e2-ba56-4e18-b5e2-52d67095e556', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_5', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='b282d3df324ad7d6f19653c532b2ba97c92c41383b194f6564891cb46026fb7a')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='At the same time, the head of Iran‚Äôs Ports and Maritime Organization (PMO) met with the \\nUAE‚Äôs ambassador to Tehran, during which the two sides stressed the acceleration of \\nmutual port, maritime, and transit cooperation.  \\nIn the meeting, UAE Ambassador Saif Mohamed Obaid Jasem Al Zaabi underlined the \\ncapacities of UAE companies for port and maritime investment in neighboring countries, \\nespecially Iran, and announced a field visit by his country‚Äôs experts to Iranian ports in the \\nnear future.  \\nThe Arab official also referred to the very good transportation and transit infrastructure \\nin his country and welcomed Iran\\'s approach to developing transit cooperation with CIS \\ncountries.  \\nAl Zaabi emphasized the need for the expansion of economic relations between Tehran \\nand Abu Dhabi, expressing the trust and interest of the UAE government in developing \\nport and maritime cooperation with Iran.  \\nPMO Head Ali -Akbar Safaei for his part stressed the strategy of the Iranian government \\nto develop economic cooperation and good relations with neighboring countries, saying \\nthat the development of maritime relations between Iran and the United Arab Emirates is \\nvery important for the Islamic Republic.  \\nStating that Iran is ready for the development of maritime, transit, and port relations with \\nAbu Dhabi, Safaei emphasized: ‚ÄúTransit and port connections between Tehran and Abu \\nDhabi with Central Asian countries and other nations can be formed quickly and prosper \\nvery fast.‚Äù  \\nThe official also welcomed any investment by UAE port and maritime companies in Iran‚Äôs \\nsouthern ports, especially Shahid Rajaei Port and Chabahar Port.  \\n\"Chabahar Port has very good capacities and the private sector of the United Arab \\nEmirates can forge long -term investment contracts in Chabahar port,\" he said.  \\n \\nNext  arti cle:  \\nSaudi Arabia ready to expand co -op with Iran\\'s \\npetchem industry', start_char_idx=0, end_char_idx=1902, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5234469417822504),\n",
      " NodeWithScore(node=TextNode(id_='438b7968-ba01-4c4f-9a68-e687d7448f2c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_4', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5b7803f6416f6ef0319c0c8b38398ea0766fe0d4962d4cac1e3c6f80d059bc68')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text=\"Pointing to the positive impact of the resumption of relations between the Islamic \\nRepublic of Iran and Saudi Arabia in the region, Al -Husseini said that the volume of trade \\nbetween the two countries has increased about 40 times.  \\n‚ÄúThis volume of trade in various fields indicates a natural and positive growth of relations \\nand interactions between Iran and the UAE, and the role of the governments of the two \\nsides is to encourage trade and facilitate it through agreements to avoid double taxation, \\nand it is necessary to revise the existing agreements between the two countries,‚Äù he said.  \\nKhandouzi for his part referred to the previous unfinished negotiations related to the \\ndrafting of a foreign investment agreement between the two sides, saying: ‚ÄúThe Islamic \\nRepublic of Iran is ready to cooperate in joint profitable projects, as well as cooperation \\nfor investing in other countries.‚Äù  \\nAlso on May 9, the head of the Federation of Chambers of Commerce and Industry of the \\nUnited Arab Emirates said his country is seeking to become Iran‚Äôs top trading partner in \\nthe region.  \\nAbdullah Mohamed Al Mazrouei, who visited Iran at the head of a business delegation, \\nmade the remarks in a meeting with the former Head of Iran Chamber of Commerce, \\nIndustries, Mines, and Agriculture (ICCIMA) Gholam -Hossein Shafeie in Tehran.  \\nDuring the meeting, the two sides exchanged views on the common fields of cooperation, \\neconomic relations, and how to expand commercial relations between the private sectors \\nof Iran and the UAE.  \\nStating that the UAE is one of the most important neighboring countries of Iran with a \\ndeep historical relationship, Shafeie said: ‚ÄúThe UAE is Iran's second trading partner in the \\nworld after China, and the volume of our annual exchanges has reached about 24 billion \\ndollars. Despite all the restrictions of the past and the heavy shadow of political issues on \\neconomic relations, the UAE has always maintained its good position in relation to Iran \\nand the mentioned issues have not been able to have a deep impact on our business \\nrelations.‚Äù  \\nBack in early January, the director -general of Bushehr Province‚Äôs Ports and Maritime \\nDepartment announced that Iran has launched a direct container shipping line from the \\ncountry‚Äôs southwestern Bushehr Port to the United Arab Emirates‚Äô Port of Jebel Ali.  \\nAccording to Mohammad Shakibi -Nasab, launching the mentioned shipping line is going to \\nboost the economic exchanges between the two countries.  \\nHe further noted that with the new line going operational the cost of transporting export \\ncargoes has also been reduced for the two sides‚Äô traders.\", start_char_idx=0, end_char_idx=2651, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5176968822735436)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iran and the United Arab Emirates (UAE) have a complex and multifaceted relationship, with both countries sharing a long history of cultural, economic, and political ties. In recent years, the relationship between the two countries has been marked by increased cooperation and mutual interest, particularly in the fields of trade, investment, and regional security.\n",
      "Trade between Iran and the UAE has recovered from a pandemic slump in 2020/2021, with bilateral trade reaching $24 billion in the 12 months ending in March 2022, according to Iranian data. The UAE is Iran's second-largest trade partner, and the two countries have been working to expand their economic ties and increase mutual investment.\n",
      "In diplomatic exchanges, Iranian officials have been asking their Emirati counterparts to find new mechanisms for financing trade and investment, and the UAE has been supportive of Iran's efforts to re-establish its economic relations with the region. The UAE has also been actively promoting trade and investment ties with Iran, including through the establishment of direct container shipping lines between the two countries.\n",
      "However, the relationship between Iran and the UAE is not without its challenges. The two countries have had disagreements over issues such as regional security, energy policy, and the role of Iran in the Middle East. Additionally, the UAE has been subject to US sanctions, which have had an impact on its economic relations with Iran.\n",
      "Overall, the relationship between Iran and the UAE is complex and multifaceted, with both countries sharing a long history of cultural, economic, and political ties. While there are challenges and disagreements, the two countries have been working to expand their economic ties and increase mutual investment, and the UAE has been actively promoting trade and investment ties with Iran.</s>"
     ]
    }
   ],
   "source": [
    "# create a query engine and query\n",
    "# response = query_engine.query(\"who studied Master of Science in Management with a background in Civil Engineering?\")\n",
    "# response = query_engine.query(\"how many gold medals Iranian youth won in 2023 chess competitions?\")\n",
    "# response = query_engine.query(\"describe key points of 2023 climate change?\")\n",
    "# response = query_engine.query(\"how much headline inflation increased after storm shock?\")\n",
    "# response = query_engine.query(\"how many ship detection methods are there? just name and use no more than 70 words\")\n",
    "response = query_engine.query(\"explain Iran's relationship with UAE?\")\n",
    "# response = query_engine.query(\"say something\")\n",
    "# response = query_engine.query(\"how many gold medals Iranian youth won in 2023 chess competitions?\")\n",
    "pprint(response.source_nodes)\n",
    "response.print_response_stream()\n",
    "# ans = []\n",
    "# for txt in response.response_gen:\n",
    "#     ans.append(txt)\n",
    "#     print(txt, sep=\"\")\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='c8ed8ecb-3135-4c5e-a3ba-6bdee40ce423', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='f7b86ebc0736c6d0519f87124fd6b20d3434e57304341e9edee468ade70c3a23')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='The UAE is Iran‚Äôs second -largest trade partner. The trade between Iran and the UAE has \\nrecovered from a pandemic slump of $11 billion in 2020/2021 to $24 billion in the 12 \\nmonths ending in March, according to Iranian data.  \\nThe trade between the two sides has surpassed the $22 billion recorded in 2012 before \\nU.S. -led sanctions were imposed on the Iranian economy.  \\nIranian officials have said they are now targeting a further increase in bilateral trade \\ntowards $30 billion in the next two years.  \\n‚ÄúPressure from the UAE central bank has decreased and some Emirati banks have started \\nopening bank accounts,‚Äù said Masoud Daneshmand, a former head of the Iran -UAE \\nChamber of Commerce. ‚ÄúCurrently, some Iranian companies that used to be in the UAE \\nbut had become inactive have become active again. Some new companies have also \\nstarted business.‚Äù  \\nIn diplomatic exchanges, Iranian officials have been asking their Emirati counterparts to \\nfind new mechanisms for financing trade, according to people briefed on these \\nconversations.  \\n‚ÄúOur economic relationship with Iran has long been of major importance,‚Äù said the UAE‚Äôs \\neconomy ministry. ‚ÄúThe UAE‚Äôs trade with Iran is conducted in full compliance with global \\nrules and standards.‚Äù  \\nFor years there have been self -imposed restrictions on business with Iran, but these have \\nbeen gradually eased in recent years, a UAE -based businessman said. ‚ÄúThere‚Äôs a sense of \\nmore openness.‚Äù  \\nIran and the United Arab Emirates have agreed to sign new memorandums of \\nunderstanding (MOUs) on the avoidance of double taxation and facilitation of mutual \\ninvestment.  \\nThe decision was made during a meeting between Iranian Minister of Finance and \\nEconomic Affairs Ehsan Khandouzi and UAE Minister of State for Financial Affairs \\nMohamed bin Hadi Al Hussaini on the sidelines of the annual meeting of the Islamic \\nDevelopment Bank (IsDB) Board of Executive Directors in Jeddah in mid -May.  \\nDuring the meeting, the officials emphasized increasing cooperation in the fields of trade \\nand foreign investment; in this regard, it was decided that appropriate measures should be \\nimplemented soon in order to sign agreements on facilitating foreign investment and \\navoidance of double taxation between the countries.', start_char_idx=0, end_char_idx=2268, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5299779336192382),\n",
       " NodeWithScore(node=TextNode(id_='e7f2d6e2-ba56-4e18-b5e2-52d67095e556', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_5', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='b282d3df324ad7d6f19653c532b2ba97c92c41383b194f6564891cb46026fb7a')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='At the same time, the head of Iran‚Äôs Ports and Maritime Organization (PMO) met with the \\nUAE‚Äôs ambassador to Tehran, during which the two sides stressed the acceleration of \\nmutual port, maritime, and transit cooperation.  \\nIn the meeting, UAE Ambassador Saif Mohamed Obaid Jasem Al Zaabi underlined the \\ncapacities of UAE companies for port and maritime investment in neighboring countries, \\nespecially Iran, and announced a field visit by his country‚Äôs experts to Iranian ports in the \\nnear future.  \\nThe Arab official also referred to the very good transportation and transit infrastructure \\nin his country and welcomed Iran\\'s approach to developing transit cooperation with CIS \\ncountries.  \\nAl Zaabi emphasized the need for the expansion of economic relations between Tehran \\nand Abu Dhabi, expressing the trust and interest of the UAE government in developing \\nport and maritime cooperation with Iran.  \\nPMO Head Ali -Akbar Safaei for his part stressed the strategy of the Iranian government \\nto develop economic cooperation and good relations with neighboring countries, saying \\nthat the development of maritime relations between Iran and the United Arab Emirates is \\nvery important for the Islamic Republic.  \\nStating that Iran is ready for the development of maritime, transit, and port relations with \\nAbu Dhabi, Safaei emphasized: ‚ÄúTransit and port connections between Tehran and Abu \\nDhabi with Central Asian countries and other nations can be formed quickly and prosper \\nvery fast.‚Äù  \\nThe official also welcomed any investment by UAE port and maritime companies in Iran‚Äôs \\nsouthern ports, especially Shahid Rajaei Port and Chabahar Port.  \\n\"Chabahar Port has very good capacities and the private sector of the United Arab \\nEmirates can forge long -term investment contracts in Chabahar port,\" he said.  \\n \\nNext  arti cle:  \\nSaudi Arabia ready to expand co -op with Iran\\'s \\npetchem industry', start_char_idx=0, end_char_idx=1902, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5234469417822504),\n",
       " NodeWithScore(node=TextNode(id_='438b7968-ba01-4c4f-9a68-e687d7448f2c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_4', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5b7803f6416f6ef0319c0c8b38398ea0766fe0d4962d4cac1e3c6f80d059bc68')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text=\"Pointing to the positive impact of the resumption of relations between the Islamic \\nRepublic of Iran and Saudi Arabia in the region, Al -Husseini said that the volume of trade \\nbetween the two countries has increased about 40 times.  \\n‚ÄúThis volume of trade in various fields indicates a natural and positive growth of relations \\nand interactions between Iran and the UAE, and the role of the governments of the two \\nsides is to encourage trade and facilitate it through agreements to avoid double taxation, \\nand it is necessary to revise the existing agreements between the two countries,‚Äù he said.  \\nKhandouzi for his part referred to the previous unfinished negotiations related to the \\ndrafting of a foreign investment agreement between the two sides, saying: ‚ÄúThe Islamic \\nRepublic of Iran is ready to cooperate in joint profitable projects, as well as cooperation \\nfor investing in other countries.‚Äù  \\nAlso on May 9, the head of the Federation of Chambers of Commerce and Industry of the \\nUnited Arab Emirates said his country is seeking to become Iran‚Äôs top trading partner in \\nthe region.  \\nAbdullah Mohamed Al Mazrouei, who visited Iran at the head of a business delegation, \\nmade the remarks in a meeting with the former Head of Iran Chamber of Commerce, \\nIndustries, Mines, and Agriculture (ICCIMA) Gholam -Hossein Shafeie in Tehran.  \\nDuring the meeting, the two sides exchanged views on the common fields of cooperation, \\neconomic relations, and how to expand commercial relations between the private sectors \\nof Iran and the UAE.  \\nStating that the UAE is one of the most important neighboring countries of Iran with a \\ndeep historical relationship, Shafeie said: ‚ÄúThe UAE is Iran's second trading partner in the \\nworld after China, and the volume of our annual exchanges has reached about 24 billion \\ndollars. Despite all the restrictions of the past and the heavy shadow of political issues on \\neconomic relations, the UAE has always maintained its good position in relation to Iran \\nand the mentioned issues have not been able to have a deep impact on our business \\nrelations.‚Äù  \\nBack in early January, the director -general of Bushehr Province‚Äôs Ports and Maritime \\nDepartment announced that Iran has launched a direct container shipping line from the \\ncountry‚Äôs southwestern Bushehr Port to the United Arab Emirates‚Äô Port of Jebel Ali.  \\nAccording to Mohammad Shakibi -Nasab, launching the mentioned shipping line is going to \\nboost the economic exchanges between the two countries.  \\nHe further noted that with the new line going operational the cost of transporting export \\ncargoes has also been reduced for the two sides‚Äô traders.\", start_char_idx=0, end_char_idx=2651, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5176968822735436)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method StreamingResponse.get_formatted_sources of StreamingResponse(response_gen=<generator object stream_completion_response_to_tokens.<locals>.gen at 0x000001C3A6457E00>, source_nodes=[NodeWithScore(node=TextNode(id_='c8ed8ecb-3135-4c5e-a3ba-6bdee40ce423', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='f7b86ebc0736c6d0519f87124fd6b20d3434e57304341e9edee468ade70c3a23')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='The UAE is Iran‚Äôs second -largest trade partner. The trade between Iran and the UAE has \\nrecovered from a pandemic slump of $11 billion in 2020/2021 to $24 billion in the 12 \\nmonths ending in March, according to Iranian data.  \\nThe trade between the two sides has surpassed the $22 billion recorded in 2012 before \\nU.S. -led sanctions were imposed on the Iranian economy.  \\nIranian officials have said they are now targeting a further increase in bilateral trade \\ntowards $30 billion in the next two years.  \\n‚ÄúPressure from the UAE central bank has decreased and some Emirati banks have started \\nopening bank accounts,‚Äù said Masoud Daneshmand, a former head of the Iran -UAE \\nChamber of Commerce. ‚ÄúCurrently, some Iranian companies that used to be in the UAE \\nbut had become inactive have become active again. Some new companies have also \\nstarted business.‚Äù  \\nIn diplomatic exchanges, Iranian officials have been asking their Emirati counterparts to \\nfind new mechanisms for financing trade, according to people briefed on these \\nconversations.  \\n‚ÄúOur economic relationship with Iran has long been of major importance,‚Äù said the UAE‚Äôs \\neconomy ministry. ‚ÄúThe UAE‚Äôs trade with Iran is conducted in full compliance with global \\nrules and standards.‚Äù  \\nFor years there have been self -imposed restrictions on business with Iran, but these have \\nbeen gradually eased in recent years, a UAE -based businessman said. ‚ÄúThere‚Äôs a sense of \\nmore openness.‚Äù  \\nIran and the United Arab Emirates have agreed to sign new memorandums of \\nunderstanding (MOUs) on the avoidance of double taxation and facilitation of mutual \\ninvestment.  \\nThe decision was made during a meeting between Iranian Minister of Finance and \\nEconomic Affairs Ehsan Khandouzi and UAE Minister of State for Financial Affairs \\nMohamed bin Hadi Al Hussaini on the sidelines of the annual meeting of the Islamic \\nDevelopment Bank (IsDB) Board of Executive Directors in Jeddah in mid -May.  \\nDuring the meeting, the officials emphasized increasing cooperation in the fields of trade \\nand foreign investment; in this regard, it was decided that appropriate measures should be \\nimplemented soon in order to sign agreements on facilitating foreign investment and \\navoidance of double taxation between the countries.', start_char_idx=0, end_char_idx=2268, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5299779336192382), NodeWithScore(node=TextNode(id_='e7f2d6e2-ba56-4e18-b5e2-52d67095e556', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_5', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='b282d3df324ad7d6f19653c532b2ba97c92c41383b194f6564891cb46026fb7a')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='At the same time, the head of Iran‚Äôs Ports and Maritime Organization (PMO) met with the \\nUAE‚Äôs ambassador to Tehran, during which the two sides stressed the acceleration of \\nmutual port, maritime, and transit cooperation.  \\nIn the meeting, UAE Ambassador Saif Mohamed Obaid Jasem Al Zaabi underlined the \\ncapacities of UAE companies for port and maritime investment in neighboring countries, \\nespecially Iran, and announced a field visit by his country‚Äôs experts to Iranian ports in the \\nnear future.  \\nThe Arab official also referred to the very good transportation and transit infrastructure \\nin his country and welcomed Iran\\'s approach to developing transit cooperation with CIS \\ncountries.  \\nAl Zaabi emphasized the need for the expansion of economic relations between Tehran \\nand Abu Dhabi, expressing the trust and interest of the UAE government in developing \\nport and maritime cooperation with Iran.  \\nPMO Head Ali -Akbar Safaei for his part stressed the strategy of the Iranian government \\nto develop economic cooperation and good relations with neighboring countries, saying \\nthat the development of maritime relations between Iran and the United Arab Emirates is \\nvery important for the Islamic Republic.  \\nStating that Iran is ready for the development of maritime, transit, and port relations with \\nAbu Dhabi, Safaei emphasized: ‚ÄúTransit and port connections between Tehran and Abu \\nDhabi with Central Asian countries and other nations can be formed quickly and prosper \\nvery fast.‚Äù  \\nThe official also welcomed any investment by UAE port and maritime companies in Iran‚Äôs \\nsouthern ports, especially Shahid Rajaei Port and Chabahar Port.  \\n\"Chabahar Port has very good capacities and the private sector of the United Arab \\nEmirates can forge long -term investment contracts in Chabahar port,\" he said.  \\n \\nNext  arti cle:  \\nSaudi Arabia ready to expand co -op with Iran\\'s \\npetchem industry', start_char_idx=0, end_char_idx=1902, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5234469417822504), NodeWithScore(node=TextNode(id_='438b7968-ba01-4c4f-9a68-e687d7448f2c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='218_4', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5b7803f6416f6ef0319c0c8b38398ea0766fe0d4962d4cac1e3c6f80d059bc68')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text=\"Pointing to the positive impact of the resumption of relations between the Islamic \\nRepublic of Iran and Saudi Arabia in the region, Al -Husseini said that the volume of trade \\nbetween the two countries has increased about 40 times.  \\n‚ÄúThis volume of trade in various fields indicates a natural and positive growth of relations \\nand interactions between Iran and the UAE, and the role of the governments of the two \\nsides is to encourage trade and facilitate it through agreements to avoid double taxation, \\nand it is necessary to revise the existing agreements between the two countries,‚Äù he said.  \\nKhandouzi for his part referred to the previous unfinished negotiations related to the \\ndrafting of a foreign investment agreement between the two sides, saying: ‚ÄúThe Islamic \\nRepublic of Iran is ready to cooperate in joint profitable projects, as well as cooperation \\nfor investing in other countries.‚Äù  \\nAlso on May 9, the head of the Federation of Chambers of Commerce and Industry of the \\nUnited Arab Emirates said his country is seeking to become Iran‚Äôs top trading partner in \\nthe region.  \\nAbdullah Mohamed Al Mazrouei, who visited Iran at the head of a business delegation, \\nmade the remarks in a meeting with the former Head of Iran Chamber of Commerce, \\nIndustries, Mines, and Agriculture (ICCIMA) Gholam -Hossein Shafeie in Tehran.  \\nDuring the meeting, the two sides exchanged views on the common fields of cooperation, \\neconomic relations, and how to expand commercial relations between the private sectors \\nof Iran and the UAE.  \\nStating that the UAE is one of the most important neighboring countries of Iran with a \\ndeep historical relationship, Shafeie said: ‚ÄúThe UAE is Iran's second trading partner in the \\nworld after China, and the volume of our annual exchanges has reached about 24 billion \\ndollars. Despite all the restrictions of the past and the heavy shadow of political issues on \\neconomic relations, the UAE has always maintained its good position in relation to Iran \\nand the mentioned issues have not been able to have a deep impact on our business \\nrelations.‚Äù  \\nBack in early January, the director -general of Bushehr Province‚Äôs Ports and Maritime \\nDepartment announced that Iran has launched a direct container shipping line from the \\ncountry‚Äôs southwestern Bushehr Port to the United Arab Emirates‚Äô Port of Jebel Ali.  \\nAccording to Mohammad Shakibi -Nasab, launching the mentioned shipping line is going to \\nboost the economic exchanges between the two countries.  \\nHe further noted that with the new line going operational the cost of transporting export \\ncargoes has also been reduced for the two sides‚Äô traders.\", start_char_idx=0, end_char_idx=2651, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5176968822735436)], metadata={'c8ed8ecb-3135-4c5e-a3ba-6bdee40ce423': {}, 'e7f2d6e2-ba56-4e18-b5e2-52d67095e556': {}, '438b7968-ba01-4c4f-9a68-e687d7448f2c': {}}, response_txt=\" Iran and the United Arab Emirates (UAE) have a complex and multifaceted relationship, with both countries sharing a long history of cultural, economic, and political ties. In recent years, the relationship between the two countries has been marked by increased cooperation and mutual interest, particularly in the fields of trade, investment, and regional security.\\nTrade between Iran and the UAE has recovered from a pandemic slump in 2020/2021, with bilateral trade reaching $24 billion in the 12 months ending in March 2022, according to Iranian data. The UAE is Iran's second-largest trade partner, and the two countries have been working to expand their economic ties and increase mutual investment.\\nIn diplomatic exchanges, Iranian officials have been asking their Emirati counterparts to find new mechanisms for financing trade and investment, and the UAE has been supportive of Iran's efforts to re-establish its economic relations with the region. The UAE has also been actively promoting trade and investment ties with Iran, including through the establishment of direct container shipping lines between the two countries.\\nHowever, the relationship between Iran and the UAE is not without its challenges. The two countries have had disagreements over issues such as regional security, energy policy, and the role of Iran in the Middle East. Additionally, the UAE has been subject to US sanctions, which have had an impact on its economic relations with Iran.\\nOverall, the relationship between Iran and the UAE is complex and multifaceted, with both countries sharing a long history of cultural, economic, and political ties. While there are challenges and disagreements, the two countries have been working to expand their economic ties and increase mutual investment, and the UAE has been actively promoting trade and investment ties with Iran.</s>\")>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get_formatted_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'190_31'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = response.source_nodes[1].node.relationships\n",
    "key = list(metadata.keys())[0]\n",
    "metadata[key].node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd = {\"a\": 1, \"b\": 2}\n",
    "list(ddd.items())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method StreamingResponse.get_formatted_sources of StreamingResponse(response_gen=<generator object stream_completion_response_to_tokens.<locals>.gen at 0x00000227EACDB5E0>, source_nodes=[NodeWithScore(node=TextNode(id_='901d0b5c-0aec-43ae-9424-595ccd14585f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b223a09c-d050-4e73-8603-644c02632f83', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='b61bb83fa485af0012e8b4018b648acb73bb7032c71d9fc5ed05b97d67fa6f9d')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='as digital photographs), or by pretraining a neural network on the satellite image domain. The latter can be \\ndone through an unsupervised pipeline using self-supervised learning (SSL) [6], a contrastive learning \\nparadigm that extracts useful patterns, learns invariances and disentangles causal factors in the training data. \\nFeatures learned this way are better adapted for transfer learning of few-shot object detectors. We propose \\nto use this paradigm to create a ship detector with few data. \\n \\nFor VHR images, a large amount of literature exists, with the number of works follow- ing the increasing \\nnumber of sensors and the quantity of publicly available data [7,8]. Many of these approaches focused on \\ndetecting ships with classical image processing pipelines: image processing using spectral indices or histograms \\n(e.g., sea-land segmentation, cloud removal), ship candidate extraction (e.g., threshold, anomaly detection, \\nsaliency), and, then, rule-based ship identification or classification using statistical methods. Virtually \\nall of these works focus on VHR images with R,G,B, and PAN bands, occasionally with the addition of \\nNIR, with resolution less than 5 m. Deep learning was applied to images with under lm resolution by using \\nobject detection convolutional neural networks (CNN): R-CNNs [9,10], YOLO [11,12], U-Net \\n \\nFor SAR imagery, [1] reviews four operational ship detectors that work on multiple sensors. All of the \\napproaches use classical processing chains and start by filtering out land pixels. This filter is either based on \\nshapefiles or on land/water segmentation masks generated from the SAR image. However, in both cases, a large \\nmargin is taken around the coastlines, eliminating any ships that are moored in ports. Deep learning was also \\napplied to SAR ship detection, with notable results detailed in [15]. \\nIn multi-spectral images, the most notable work is [4] which uses SVMs to identify water, cloud, and land \\npixels and then builds a CNN to fuse multiple spectral channels. This fusion network predicts whether \\nobjects in the water are ships. Other approaches, such as [3], rely on hand made rules on size and spectral \\nvalues to distinguish between ships, clouds, islands, and icebergs. The only Sentinel 2 ship dataset \\npublicly available is [16] but it only includes small size image chips and weak annotations for precise \\nlocalization, \\n1. e., a single point for each ship, obtained by geo-referencing AIS GPS coordinates to pixel coordinates in \\nthe chips. \\nAlthough large datasets exist for VHR images, for Sentinel-2 none are available with pixel level \\nannotations while usually thousands of examples are needed to train deep learning object detectors. Few-\\nshot learning based approaches can bring interesting perspectives for remote sensing in general and in our \\nsetting in particular. Few-shot learning consists in training a neural network with few labeled samples, \\nmost often thanks to quality feature extractors upon which transfer learning is performed. One recent method \\nfor unsupervised learning of features extractors that enable few-shot learning is contrastive self-supervised \\nlearning [6,17]. Contrastive SSL relies on a \"pretext training task\", defined by the practitioner, that helps \\nthe network to learn invariances and latent patterns in the data [18-20]. \\nSeveral strategies exist for choosing the pretext task: context prediction [21], jigsaw puzzle, or simply by \\nconsidering various augmented views. The latter is used by [22,23] for remote sensing applications like land \\nuse classification and change detection. \\nContributions \\nIn this work, we make two contributions: \\n(1)  \\nA deep learning pipeline for ship detection with few training \\nexamples. We take advantage of self-supervised learning to learn features on large non-annotated datasets \\nof Sentinel 2 images and we learn a ship detector using few-shot transfer learning; \\n(2)  \\nA novel Sentinel 2 ship detection dataset, with 16 images of harbours \\nwith a total of 1053 ship annotations at the pixel level. \\n2. Materials and Methods \\nOur approach is based on a U-Net architecture with a ResNet-50 backbone to produce binary ship/no-ship', start_char_idx=0, end_char_idx=4189, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.36622370828842393), NodeWithScore(node=TextNode(id_='2ba47058-556c-495d-8e3e-97554d863b62', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e321c9ed-a609-477b-9ac2-6de365c2b391', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='a3e9daa4a16d6bfe5ed56b01c1b50ad20345380f87c6a8d5c226686d02a87566')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='All of the articles bellow are discussing Ship detection using satellite imagery with Machine \\nlearning models and AI ‚Äì our purpose is to provide beneficial information in order to \\nconduct research on the ship detection topic:  \\nArticle 1: \\nName of Article: Ship detection on Sentinel-2 images with Mask R-CNN model \\nAuthor: Andrea C. \\n \\nA time analysis of maritime traffic using PyTorch and open data \\nAs part of a larger ML project, we decided to explore the possibility to assess \\nmaritime traffic using publicly available satellite images. In particular, our goal \\nwas to estimate a time series that is representative of the volume of the maritime \\ntraffic observed over time in a given region. In this article, we discuss the \\nmethodology and results obtained. \\nNote: all code discussed in the following is available on my personal GitHub at \\nhttps://github.com/andrea-ci/s2-ship-detection. \\nWhy satellite data \\nPhoto by Matthijs van Heerikhuize on Unsplash \\nSatellite‚Äôs gone up to the skies \\nThings like that drive me out of my mind \\nI watched it for a little while \\nI like to watch things on TV \\nLou Reed, ‚ÄúSatellite of love‚Äù \\nIn the last years, remote sensing has dramatically evolved and so have other fields \\nsuch as computer vision and machine learning. In addition, more and more satellite \\nimagery has become publicly available. Notable examples include Landsat and \\nSentinel-2 constellation imagery. \\nSatellites exhibit three fundamental advantages for the users: \\nthey allow access to information that is often difficult to obtain by other means; \\nthey provide a global geographic coverage;', start_char_idx=0, end_char_idx=1606, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.3474833078303168), NodeWithScore(node=TextNode(id_='e16582a1-eb34-45fa-ab6a-b7308dc91666', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ddb9f2fd-2670-43db-88f4-543205bd88c0', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='faff90c706a8e98b3c76b131ecf971b2f245c4b9eb40ed9b7d4ddf0f2c311d7f')}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='procedure, we learn good features on Sentinel-2 images, without requiring labeling, to initialize our network\\'s \\nbackbone. The full net- work is then fine-tuned to learn to detect ships in challenging settings. We evaluated this \\napproach versus pre-training on ImageNet and versus a classical image processing pipeline. We examined the impact \\nof variations in the self-supervised learning step and we show that in the few-shot learning setting self-supervised \\npre-training achieves better results than ImageNet pre-training. When enough training data are available , our self -\\nsupervised approach is as good as ImageNet pre-training . We conclude that a better design of the self-supervised \\ntask and bigger non-annotated dataset sizes can lead to surpassing ImageNet pre-training performance without any \\nannotation costs. \\n1. Introduction \\nShip detection is an important challenge in economic intelligence and maritime secu- rity, with \\napplications in detecting piracy or illegal fishing and monitoring logistic chains. For now, cooperative \\ntransponders systems, such as AIS, provide ship detection and identification for maritime surveillance. However, \\nsome ships may have non-functioning transponders; many times they are turned off on purpose to hide ship \\nmovements. Mar- itime patrols can help to identify suspect ships, but this requires many resources and \\ntheir range is restricted. Therefore, using satellites, such as those from the European Space Agency Sentinel-\\n2 mission, to detect ships in littoral regions is a promising solution thanks to their large swath and high \\nrevisit time. \\nSome commercial satellite constellations offer very high resolution images (VHR) (<1 m/pixel) \\nwith low revisit time (1-2 days). However, VHR images are usually limited to the R, G, B bands and \\nimage analysis on such high resolution images is computationally intensive. On the other hand, synthetic \\naperture radar (SAR) satellites can also be used, although their resolution is lower than VHR optical \\nsources (e.g., Sentinel 1 has 5 m resolution), the analysis of their imagery is the main approach to \\nship detection since SAR images can be acquired irrespective of cloud cover and the day and night cycle. The \\ndownsides of SAR are low performance in rough sea conditions, but, most importantly, detection is only \\ndone on seas away from land and is not possible for moored ships in harbor or for ships smaller than 10 \\nm [1]. Furthermore, SAR is vulnerable to jamming [2]. \\n \\nThe Copernicus Sentinel-2 mission of the European Space Agency offers free multi- spectral images with a \\nrefresh rate of maximum 5 days and a resolution down to 10 m, as detailed in Table 1. Our work \\nfocuses on this data source for several reasons. First, multi-spectral information allows to better extract a ship \\nfingerprint and distinguish it from land or man-made structures, as shown in [3,4]. Second, a multi-spectral \\noptical learning based approach can perform detection in both high seas and harbor contexts, while \\nalso removing the requirement of storing a vector map of coastlines and performing cloud removal as a pre-\\nprocessing step. Thus, it could be adapted to a real-time, on-board satellite setting and is not affected by jamming. \\n \\n \\nAlthough ship detection is a challenging task, ship identification in remote-sensing images is even more \\ndifficult [5]. A coarse identification could be made by ship type (container ship, fishing vessel, barge, \\ncruiseliner, etc.) using supervised classification, with accuracy that should be closely related to image \\nresolution. However, to establish ship identity uniquely, it does not seem feasible with the Sentinel-2 sensor \\nto extract features fit for this purpose, such as measurement of ships to meter precision, extracting exact \\ncontours, or detecting salient unique traits of different ships. Our work focuses on detection but the \\napproach is generic and could be extended to other sensors with better resolution, eventually allowing \\nidentification. \\nRecent remote sensing approaches based on machine learning require large amounts of annotated data. Some \\nefforts to collect and annotate data have been made for VHR images, for SAR and for Sentinel 2, but, for the \\nlatter, these works did not target ship detection in particular. For object detection using convolutional neural \\nnetworks (CNN), an interesting way to overcome the lack of data is to use transfer learning. This is achieved \\neither by using CNNs pretrained on large labeled data sets gathered in a sufficiently \"close\" domain (such \\nhigh-resolution', start_char_idx=0, end_char_idx=4578, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.33616504860817364)], metadata={'901d0b5c-0aec-43ae-9424-595ccd14585f': {}, '2ba47058-556c-495d-8e3e-97554d863b62': {}, 'e16582a1-eb34-45fa-ab6a-b7308dc91666': {}}, response_txt=' There are several ship detection methods, including:\\n1. Ship detection using satellite imagery with machine learning models\\n2. Contrastive self-supervised learning for few-shot transfer learning\\n3. Sentinel-2 ship detection dataset\\n4. Unsupervised learning of features extractors for few-shot learning\\n5. Deep learning-based approaches\\n6. Classical image processing pipelines\\n7. Object detection convolutional neural networks (CNN)</s>')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get_formatted_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('as digital photographs), or by pretraining a neural network on the satellite '\n",
      " 'image domain. The latter can be \\n'\n",
      " 'done through an unsupervised pipeline using self-supervised learning (SSL) '\n",
      " '[6], a contrastive learning \\n'\n",
      " 'paradigm that extracts useful patterns, learns invariances and disentangles '\n",
      " 'causal factors in the training data. \\n'\n",
      " 'Features learned this way are better adapted for transfer learning of '\n",
      " 'few-shot object detectors. We propose \\n'\n",
      " 'to use this paradigm to create a ship detector with few data. \\n'\n",
      " ' \\n'\n",
      " 'For VHR images, a large amount of literature exists, with the number of '\n",
      " 'works follow- ing the increasing \\n'\n",
      " 'number of sensors and the quantity of publicly available data [7,8]. Many of '\n",
      " 'these approaches focused on \\n'\n",
      " 'detecting ships with classical image processing pipelines: image processing '\n",
      " 'using spectral indices or histograms \\n'\n",
      " '(e.g., sea-land segmentation, cloud removal), ship candidate extraction '\n",
      " '(e.g., threshold, anomaly detection, \\n'\n",
      " 'saliency), and, then, rule-based ship identification or classification using '\n",
      " 'statistical methods. Virtually \\n'\n",
      " 'all of these works focus on VHR images with R,G,B, and PAN bands, '\n",
      " 'occasionally with the addition of \\n'\n",
      " 'NIR, with resolution less than 5 m. Deep learning was applied to images with '\n",
      " 'under lm resolution by using \\n'\n",
      " 'object detection convolutional neural networks (CNN): R-CNNs [9,10], YOLO '\n",
      " '[11,12], U-Net \\n'\n",
      " ' \\n'\n",
      " 'For SAR imagery, [1] reviews four operational ship detectors that work on '\n",
      " 'multiple sensors. All of the \\n'\n",
      " 'approaches use classical processing chains and start by filtering out land '\n",
      " 'pixels. This filter is either based on \\n'\n",
      " 'shapefiles or on land/water segmentation masks generated from the SAR image. '\n",
      " 'However, in both cases, a large \\n'\n",
      " 'margin is taken around the coastlines, eliminating any ships that are moored '\n",
      " 'in ports. Deep learning was also \\n'\n",
      " 'applied to SAR ship detection, with notable results detailed in [15]. \\n'\n",
      " 'In multi-spectral images, the most notable work is [4] which uses SVMs to '\n",
      " 'identify water, cloud, and land \\n'\n",
      " 'pixels and then builds a CNN to fuse multiple spectral channels. This fusion '\n",
      " 'network predicts whether \\n'\n",
      " 'objects in the water are ships. Other approaches, such as [3], rely on hand '\n",
      " 'made rules on size and spectral \\n'\n",
      " 'values to distinguish between ships, clouds, islands, and icebergs. The only '\n",
      " 'Sentinel 2 ship dataset \\n'\n",
      " 'publicly available is [16] but it only includes small size image chips and '\n",
      " 'weak annotations for precise \\n'\n",
      " 'localization, \\n'\n",
      " '1. e., a single point for each ship, obtained by geo-referencing AIS GPS '\n",
      " 'coordinates to pixel coordinates in \\n'\n",
      " 'the chips. \\n'\n",
      " 'Although large datasets exist for VHR images, for Sentinel-2 none are '\n",
      " 'available with pixel level \\n'\n",
      " 'annotations while usually thousands of examples are needed to train deep '\n",
      " 'learning object detectors. Few-\\n'\n",
      " 'shot learning based approaches can bring interesting perspectives for remote '\n",
      " 'sensing in general and in our \\n'\n",
      " 'setting in particular. Few-shot learning consists in training a neural '\n",
      " 'network with few labeled samples, \\n'\n",
      " 'most often thanks to quality feature extractors upon which transfer learning '\n",
      " 'is performed. One recent method \\n'\n",
      " 'for unsupervised learning of features extractors that enable few-shot '\n",
      " 'learning is contrastive self-supervised \\n'\n",
      " 'learning [6,17]. Contrastive SSL relies on a \"pretext training task\", '\n",
      " 'defined by the practitioner, that helps \\n'\n",
      " 'the network to learn invariances and latent patterns in the data [18-20]. \\n'\n",
      " 'Several strategies exist for choosing the pretext task: context prediction '\n",
      " '[21], jigsaw puzzle, or simply by \\n'\n",
      " 'considering various augmented views. The latter is used by [22,23] for '\n",
      " 'remote sensing applications like land \\n'\n",
      " 'use classification and change detection. \\n'\n",
      " 'Contributions \\n'\n",
      " 'In this work, we make two contributions: \\n'\n",
      " '(1)  \\n'\n",
      " 'A deep learning pipeline for ship detection with few training \\n'\n",
      " 'examples. We take advantage of self-supervised learning to learn features on '\n",
      " 'large non-annotated datasets \\n'\n",
      " 'of Sentinel 2 images and we learn a ship detector using few-shot transfer '\n",
      " 'learning; \\n'\n",
      " '(2)  \\n'\n",
      " 'A novel Sentinel 2 ship detection dataset, with 16 images of harbours \\n'\n",
      " 'with a total of 1053 ship annotations at the pixel level. \\n'\n",
      " '2. Materials and Methods \\n'\n",
      " 'Our approach is based on a U-Net architecture with a ResNet-50 backbone to '\n",
      " 'produce binary ship/no-ship')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.source_nodes[0].node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in response.response_gen:\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\NLP 1\\RAG-webapp\\main\\utilities\\RAG_with_Vectordb.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP%201/RAG-webapp/main/utilities/RAG_with_Vectordb.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39msource_nodes:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP%201/RAG-webapp/main/utilities/RAG_with_Vectordb.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(node\u001b[39m.\u001b[39mscore)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP%201/RAG-webapp/main/utilities/RAG_with_Vectordb.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m response\u001b[39m.\u001b[39msource_nodes[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.score)\n",
    "response.source_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import hashlib\n",
    "\n",
    "def hash_file(file_path):\n",
    "    # BUF_SIZE is totally arbitrary, change for your app!\n",
    "    BUF_SIZE = 65536  # lets read stuff in 64kb chunks!\n",
    "\n",
    "    hashes = dict()\n",
    "    md5 = hashlib.md5()\n",
    "    sha256 = hashlib.sha256()\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            data = f.read(BUF_SIZE)\n",
    "            if not data:\n",
    "                break\n",
    "            md5.update(data)\n",
    "            sha256.update(data)\n",
    "            \n",
    "    hashes[\"md5\"] = md5.hexdigest()\n",
    "    hashes[\"sha1\"] = sha256.hexdigest()\n",
    "    \n",
    "    return hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'md5': '9380c870db48323c8168b2ceb62bfd23',\n",
       " 'sha1': '534a586bd90d36a2153fe945eb8f1e211e71d1c4c156dcb6d53d092bea475853'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\user2\\Desktop\\RAG_Docs\\Climate_change_20232.pdf\"\n",
    "hash_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'md5': 'f3a9d00e7b1c3f4b40ae44f82a5fcb64',\n",
       " 'sha1': 'cb3ea5988bdea06d2d1ee0b4bd5f0664b518039b0261d7e87b4414d249e27b6a'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\user2\\Desktop\\RAG_Docs\\Iran medals in Asia competitions 2023.pdf\"\n",
    "hash_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002991914749145508\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "file_path = r\"C:\\Users\\user2\\Desktop\\RAG_Docs\\Climate_change_20232 - Copy.pdf\"\n",
    "t1 = time.time()\n",
    "hash_file(file_path)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
